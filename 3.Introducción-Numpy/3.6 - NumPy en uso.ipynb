{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Escuela de Ingeniería de Sistemas y Computación  \n",
    "Universidad del Valle  \n",
    "INTRODUCCIÓN A LA PROGRAMACIÓN PARA ANALÍTICA  \n",
    "Profesor: Ph.D, Robinson Duque (robinson.duque@correounivalle.edu.co)  \n",
    "Última modificación: Julio de 2020  \n",
    "\n",
    "---\n",
    "\n",
    "# Consideraciones:\n",
    "\n",
    "Este material presenta textos y ejemplos orientados al propósito del curso de _Introducción a la Programación para Analítica_ de la Universidad del Valle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de NumPy (Procesamiento de datos)\n",
    "Ahora empezaremos a utilizar los conceptos aprendidos sobre NumPy: \n",
    "* Primero estudiaremos un dataset que contiene valores de estaturas y pesos de 10.000 hombres y mujeres\n",
    "* Por ahora realizaremos una revisión y análisis indepemendiente de cada columna de datos\n",
    "* Nos daremos cuenta que analizar columnas de manera independiente no es lo más apropiado\n",
    "* Pronto aprenderemos a utilizar Pandas que nos permitirá analizar heterogéneos en una sola estructura de datos\n",
    "\n",
    "Por ahora lo que haremos será cargar las librerías de `Pandas` y `NumPy`, luego cargaremos los datos utilizando la función `read_csv` que ofrece `Pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Librería que nos permitirá cargar los datos fácilmente\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('weight-height.csv') # Se leen los datos incluidos en el dataset\n",
    "print(data.head()) # Con Pandas puedo revisar la cabecera de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de estaturas con NumPy\n",
    "> Lo primero que haremos será tomar la columna de estaturas y cargarla a un arreglo de NumPy. Luego vamos a revisar la cantidad y el tipo de datos que estamos tratando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomo las estaturas y las convierto a array\n",
    "heights = np.array(data['Height']) \n",
    "print(heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heights.size)\n",
    "print(heights.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observe que tenemos en total 10.000 datos y adicionalmente todos los datos fueron cargados como `float64`, lo cual son buenas noticias puesto que en la carga de datos no se identificaron valores que no pudieran ser convertidos a números flotantes. \n",
    ">\n",
    ">Por ejemplo, en el caso de haber encontrado valores que no fuesen numéricos, quizá el array sería de tipo `object`. No obstante, `float64` **no indica que todos los datos estén bien...**\n",
    ">\n",
    "> Observa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(heights) #Esto genera un NaN, ¿porqué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NaN: Not a Number**  \n",
    "> * Como los datos vienen en muchas formas, la librería `Pandas` tiene como objetivo ser flexible respecto al manejo de los datos faltantes (al momento de cargarlos) \n",
    "> *  NaN es el marcador de valor faltante\n",
    "> * Este valor se utiliza con datos faltantes de diferentes tipos: punto flotante, entero, booleano y objeto general\n",
    "> * En muchos casos, sin embargo, aparecerá el `None` de Python y también lo consideraremos como un dato que \"falta\" o `NA` \"no disponible\" \n",
    ">\n",
    ">La suma arroja `NaN` y esto nos indica que tenemos valores faltantes.\n",
    ">\n",
    "> Hay que tener en cuenta que en Python (y NumPy), los `nan` no se comparan con `==`, pero los `None` si. Tenga en cuenta que Pandas y NumPy usan el hecho de que `np.nan! = np.nan`, y tratan a `None` como `np.nan`.\n",
    ">\n",
    "> Si deseas saber más al respecto, te sugiero [esta lectura](https://towardsdatascience.com/navigating-the-hell-of-nans-in-python-71b12558895b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(np.nan))\n",
    "print(type(float('nan')))\n",
    "#int(np.nan) #No se puede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(None == None)\n",
    "print(np.nan == np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(None is None)\n",
    "print(np.nan is np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formas de identificar valores faltantes en NumPy y en Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "var = float('nan')\n",
    "\n",
    "var is np.nan #results in False\n",
    "#or\n",
    "np.isnan(var) #results in True\n",
    "#or\n",
    "pd.isna(var) #results in True\n",
    "#or\n",
    "pd.isnull(var)#results in True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Muy bien, ahora busquemos cúantos valores faltantes hay en nuestros datos de estaturas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Búsqueda de nan\n",
    "mascara1 = np.isnan(heights)\n",
    "print(mascara1.sum())\n",
    "\n",
    "#Búsqueda de None\n",
    "mascara2 =   heights[heights is None]\n",
    "print(mascara2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observa que tenemos 4 valores que son `nan` y no aparece ningún valor `None`(Estos último valores usualmente aparecen en arreglos de objetos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Los NaN equivalen tan solo al {}% de los datos.\".format((4/10000)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Más adelante en el curso estudiaremos otras técnicas para tratar datos faltantes cuya eliminación podrían impactar negativamente el conjunto de datos.\n",
    ">\n",
    "> Como son pocos datos (para este caso), entonces procederemos a usar todos los datos que no son NaN, para esto usamos la negación de la máscara `~mascara1` como filtro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = heights[~mascara1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota que ahora la suma ha funcionado, por consiguiente podemos pensar que todos nuestros datos faltantes han sido eliminados...\n",
    ">\n",
    ">¿Será esto suficiente para pensar que los datos están limpios?\n",
    ">\n",
    "> Observa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Promedio:           \", heights.mean())\n",
    "print(\"Std:                \", heights.std())\n",
    "print(\"Valor mínimo        \", heights.min())\n",
    "print(\"Valor máximo.       \", heights.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observa que el valor mínimo es un número negativo, ¿porqué?¿cuántos valores habrán así?\n",
    ">\n",
    "> Observa el valor máximo...\n",
    "> \n",
    "> Una forma fácil de revisar esto puede ser utilizando la función `np.unique`, que adicionalmente entrega los valores ordenados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(heights) \n",
    "#np.unique(heights, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observa que aparecen algunos valores con -1 y 0, quizá fueron valores que no se ingresaron al registro original. Depués de estos valores, el valor de la estatura mínima es 54.26313333.\n",
    ">\n",
    "> Averiguemos el número de estos valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara3 = (heights<=0)\n",
    "mascara3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Al igual que con nuestros valores faltantes, estos 3 registros corresponden tan solo al 0.03% de los datos iniciales y los podremos eliminar: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = heights[~mascara3]\n",
    "print(heights.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora revisemos nuestros datos de nuevo\n",
    "np.unique(heights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ahora observa que para el valor máximo hay uno o varios valores que contienen el valor de '710.79017576', esto pudo haber sido un error en la entrada de datos, pareciera el el punto está movido una unidad hacia la derecha (Podemos arreglarlo o eliminarlo), vamos a arreglarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara4 = heights>=79\n",
    "mascara4.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observa que sólo es un valor y para arreglarlo sólo tendríamos que dividirlo por 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights[mascara4] = heights[mascara4]/10\n",
    "np.unique(heights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Promedio:           \", heights.mean())\n",
    "print(\"Std:                \", heights.std())\n",
    "print(\"Valor mínimo:       \", heights.min())\n",
    "print(\"Valor máximo:       \", heights.max())\n",
    "print(\"Mediana:            \", np.median(heights))\n",
    "print(\"Percentil  25%:     \", np.percentile(heights, 25))\n",
    "print(\"Percentil  50%:     \", np.percentile(heights, 50))\n",
    "print(\"Percentil  75%:     \", np.percentile(heights, 75))\n",
    "print(\"Percentil  90%:     \", np.percentile(heights, 90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ahora los datos están listos para ser graficados. Más adelante en el curso entraremos en los detalles de la librería `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt  # Importación de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(heights, bins=50)\n",
    "plt.title('Distribuciones de estaturas')\n",
    "plt.xlabel('Estatura (cm)')\n",
    "plt.ylabel('Número');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar datos limpios en disco..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ahora que sabemos que nuestros datos están limpios, puedo proceder a guardarlos en un nuevo archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Se crea un dataframe utilizando un diccionario asociado con el arreglo de Numpy\n",
    "df = pd.DataFrame({'Height': heights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opción para guardar conservando los índices\n",
    "df.to_csv(\"Height-limpio.csv\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opción para guardar sin índices\n",
    "df.to_csv(\"Height-limpio-noindex.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> También podemos guardar múltiples columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#También se pueden guardar múltiples columnas, en caso que se hayan procesado más \n",
    "# de una columna. Por ejemplo, asuma que se desean clasificar las personas como altas o bajas\n",
    "# asumiendo que una estatura mayor de 1.7 mts es considerada como alta:\n",
    "\n",
    "EsAlto=np.empty(heights.size,dtype=\"U4\")\n",
    "m = ((heights*0.0254)>1.7) #Las estaturas están en pulgadas y se convierten a metros\n",
    "EsAlto[m] = \"ALTO\"\n",
    "EsAlto[~m] = \"BAJO\"\n",
    "EsAlto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo un dataframe con un diccionario asociado con las alturas y la nueva clasificación\n",
    "df = pd.DataFrame({'Height': heights,\n",
    "                  'Alto-Bajo':EsAlto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opción para guardar sin índices\n",
    "df.to_csv(\"Height-alto-bajo-noindex.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Ventajas y desventajas de lo visto\n",
    "> * Uso de funciones vectorizadas (ufunctions) \n",
    "> * Facilidad para filtrar y operar sobre los datos de un mismo tipo\n",
    "> * Facilidad para operar valores faltantes/erroneos\n",
    "> * Si quisieramos procesar: género, estatura y peso del conjunto  de datos inicial estaríamos restringidos por los tipos de datos de los arreglos y se tendrían que manejar de forma independiente\n",
    "> * Eliminar un registro o valor de un arreglo, implicaría un trabajo adicional (eliminación en otros arreglos para mantener la consistencia)\n",
    "> * Limitaciones para la creación de nuevas columnas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
